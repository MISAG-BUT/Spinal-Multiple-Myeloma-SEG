Metadata-Version: 2.4
Name: spinal-multiple-myeloma-seg
Version: 0.1.0
Summary: Tools and scripts for Spinal-Multiple-Myeloma-SEG
Author: MISAG-BUT
License: MIT
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Medical Science Apps.
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch
Requires-Dist: torchvision
Requires-Dist: pydicom
Requires-Dist: napari[all]
Requires-Dist: SimpleITK
Dynamic: license-file


# Spinal-Multiple-Myeloma-SEG

![Graphical Abstract](graphical_abstract.png "Overview of the dataset creation pipeline and data structure.")

## Overview
Welcome to the repository for the paper **"Spinal-Multiple-Myeloma-SEG"**! This repository provides the code for the implementation of the networks for segmentation within the popular [nnUNet framework](https://github.com/MIC-DKFZ/nnUNet).

### Read the [paper](TO BE Updated): 

**Authors:** Michal Nohel<sup>1,â€ </sup>, Vlastimil Valek<sup>2,3,â€ </sup>, Tomas Rohan<sup>2,3</sup>, Martin Stork<sup>4</sup>, Roman Jakubicek<sup>1</sup>, Jiri Chmelik<sup>1,â€ â€ ,</sup>*, Marek Dostal<sup>2,5,â€ â€ ,*</sup>*

**Author Affiliations:**  
<sup>1</sup> Department of Biomedical Engineering, Faculty of Electrical Engineering and Communication, Brno University of Technology, Brno, Czech Republic  
<sup>2</sup> Department of Radiology and Nuclear Medicine, University Hospital Brno, Brno, Czech Republic  
<sup>3</sup> Department of Radiology and Nuclear Medicine, Faculty of Medicine, Masaryk University, Brno, Czech Republic  
<sup>4</sup> Internal Hematology and Oncology Clinic, University Hospital Brno, Brno, Czech Republic  
<sup>5</sup> Department of Biophysics, Masaryk University, Brno, Czech Republic  

<sup>*</sup> Corresponding authors: Marek Dostal (Dostal.Marek@fnbrno.cz), Jiri Chmelik (chmelikj@vut.cz)  
<sup>â€ </sup> These authors contributed equally to this work  
<sup>â€ â€ </sup> These authors contributed equally to this work



The repository contains two main scripts:  
1. A script for visualizing the dataset, allowing you to explore the spinal and myeloma images used.  
2. A script for performing segmentation predictions on the spine and myeloma regions. These predictions were utilized to create the myeloma database used in the study.  

Together, these scripts allow researchers to reproduce the dataset preparation and segmentation workflows described in the paper.

---

## Trained Models / Zenodo
Pre-trained nnU-Net models for this project are available on Zenodo. These models were trained for segmentation of spine, vertebrae, and osteolytic spinal multiple myeloma lesions in dual-energy CT data.

- The models were created as part of the dataset preparation and annotation pipeline for **Spinal-Multiple-Myeloma-SEG**, released via [The Cancer Imaging Archive (TCIA)](https://doi.org/10.7937/k4qv-hh78).
- Spine and vertebrae segmentation models were trained on **conventional CT data** from the VerSe2020 dataset, as well as on a combined VerSe2020 + multiple myeloma dataset. These masks were used to localize the spinal region and define spatial cropping for downstream lesion segmentation.
- Lesion segmentation models were trained exclusively on **VMI 40 keV images** using an iterative semi-automatic annotation workflow.
- All models operate on **NIfTI (.nii.gz)** inputs and are intended for **research and development purposes only**.

**Links:**
- Zenodo repository with trained models can be downloaded from Zenodo repositoy: [Spinal-Multiple-Myeloma-SEG_nnUNet_models](https://zenodo.org/uploads/18598645)
- Zenodo snapshot of GitHub repo: [https://zenodo.org/records/18596640](https://zenodo.org/records/18596640)
- Zenodo DOI: [https://doi.org/10.5281/zenodo.15878952](https://doi.org/10.5281/zenodo.15878952)

A more detailed description of the models, training data, and processing pipeline is provided in the accompanying Zenodo README file.

---

## Usage
### Installation

#### Environment Setup for nnUNet Prediction (Python 3.13)
This guide explains how to set up the environment for running predictions with [nnUNet](https://github.com/MIC-DKFZ/nnUNet) on the [Spinal-Multiple-Myeloma-SEG](https://github.com/MISAG-BUT/Spinal-Multiple-Myeloma-SEG) project.
Check out the official [nnUNet installation instructions](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/installation_instructions.md)

**Note:** This pipeline has been tested on both Linux and Windows systems with GPUs:  

- **Linux:**  
  - GPU: Nvidia Titan Xp, 12 GB GDDR5  
  - CPU: Intel Core i9-12900KF, 8+8/24 cores/threads, 2.4/3.2 GHz  
  - RAM: 64 GB DDR5  
  - Storage: 1 TB SSD (system), 4 TB HDD RAID5 (data)  
  - OS: Ubuntu 24.04  

- **Windows:**  
  - GPU: EVGA GeForce RTX 3090, 24 GB GDDR6  
  - CPU: Intel Core i9-10900KF, 10/20 cores/threads, 3.7 GHz  
  - RAM: 64 GB  
  - Storage: 2 TB SSD M.2 (system)  
  - OS: Windows 10  

> âš  **Important:** The script defaults to Linux-style multiprocessing. On a clean Windows setup, nnU-Net batch prediction may fail due to multiprocessing issues.  
> If segmentation fails, use **Variant 2** in the `run_nnunet_inference` function in `utils.py`, which runs predictions sequentially without multiprocessing. This is slower but safe on Windows.

---
#### Step 1: Install Python and Clone Repository
First, download and install Python 3.13.x from [python.org](https://www.python.org/downloads/). We used Python 3.13.5.  
During installation, make sure to check **"Add Python to PATH"**.  


Create a virtual environment inside the project folder. Replace <path-to-your-python-executable> with the path to Python 3.13 on your system:
```bash
<path-to-your-python-executable> -m venv venv_run_nnUNet_prediction
```

Examples:
- Windows
```bash
C:\Users\<username>\AppData\Local\Programs\Python\Python313\python.exe -m venv venv_run_nnUNet_prediction
```
- Linux/macOS
```bash
python3.13 -m venv venv_run_nnUNet_prediction
```

Activate the environment:
- Windows
```bash
venv_run_nnUNet_prediction\Scripts\activate
```
- Linux/macOS
```bash
source venv_run_nnUNet_prediction/bin/activate
```

When activated, your prompt should show (venv_run_nnUNet_prediction).

#### Step 2: Install Core Dependencies
Install required packages starting with PyTorch. For CUDA 12.6 run:
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126
```
Clone the nnUNet repository, move into it, and install in editable mode:
```bash
git clone https://github.com/MIC-DKFZ/nnUNet.git
cd nnUNet
pip install -e .
cd ..
```

Clone the project repository and move into the project folder:

```bash
git clone https://github.com/MISAG-BUT/Spinal-Multiple-Myeloma-SEG.git
cd Spinal-Multiple-Myeloma-SEG
pip install -e .
cd ..
```

#### Step 3: Additional / Optional Packages (napari / Qt)

The GUI viewer relies on `napari`, which requires a working Qt backend.  
Depending on your operating system, additional system libraries may be needed.

> ðŸ’¡ **Tip:** If `napari` fails to start (Qt errors, missing plugins, or XCB issues), install the OS-specific dependencies below.

##### Linux (tested on Ubuntu)

On Linux, you may need extra Qt/XCB system libraries:

```bash
sudo apt install \
  libxcb-xinerama0 \
  libxkbcommon-x11-0 \
  libxcb-cursor0 \
  libxcb-icccm4 \
  libxcb-keysyms1 \
  libxcb-randr0 \
  libxcb-render-util0 \
  libxcb-xfixes0 \
  libxcb-shape0 \
  libxcb-sync1 \
  libxcb-xkb1
```

Then install the Python packages:

```bash
# Napari viewer for GUI visualization
pip install napari

# Full napari installation with optional plugins (recommended)
pip install -U 'napari[all]'
```

##### Windows

On Windows, installing the full napari package with Qt dependencies is usually sufficient:

```bash
pip install -U 'napari[all]'
```

If you experience GUI issues, make sure your environment uses a compatible Qt backend (PyQt5 is installed automatically via `napari[all]`).


#### Full Setup Summary
For convenience, a full setup summary:
```bash
<path-to-your-python-executable> -m venv venv_run_nnUNet_prediction
# Activate the environment
# Windows:
venv_run_nnUNet_prediction\Scripts\activate
# Linux/macOS:
source venv_run_nnUNet_prediction/bin/activate

pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126
git clone https://github.com/MIC-DKFZ/nnUNet.git
cd nnUNet
pip install -e .
cd ..
git clone https://github.com/MISAG-BUT/Spinal-Multiple-Myeloma-SEG.git
cd Spinal-Multiple-Myeloma-SEG
pip install -e .
cd ..

# Optional / additional packages
pip install pydicom napari
pip install -U 'napari[all]'
```

Always replace <path-to-your-python-executable> with the correct path on your system. For different CUDA versions or CPU-only setups, check the [PyTorch installation guide](https://pytorch.org/get-started/locally/).

---

## Path Configuration
Before running the project, you need to edit the `config.py` file and set the correct paths to your data and output directories according to your environment.

---

Running the Pipeline / Inference
===============================

This repository provides two complementary ways of working with the
Spinal-Multiple-Myeloma-SEG data:

1. Data visualization and qualitative inspection using Python scripts (recommended first step)
2. Full nnU-Netâ€“based segmentation pipeline for automatic inference
3. Optional command-line inference using the default nnU-Net CLI


---------------------------------------------------------------------
Data Visualization and Inspection
---------------------------------------------------------------------

Visualization Script
--------------------
**`Database_viewer_final.py`**

This script is intended for qualitative inspection of the dataset and segmentation
results. It loads multiple CT reconstructions from DICOM data, overlays spine and
lesion segmentation masks, and visualizes everything using **Napari**.

The script can be executed both:
- directly from the command line, and
- interactively from an IDE such as VS Code.


Loaded Data
-----------
For a selected patient, the script automatically detects and loads the following
DICOM series based on the SeriesDescription metadata:

- Conventional CT (ConvCT)
- Virtual Monoenergetic Images (VMI):
  - 40 keV
  - 80 keV
  - 120 keV
- Calcium Suppression reconstructions:
  - 25 Index
  - 50 Index
  - 75 Index
  - 100 Index

In addition, the script loads segmentation masks in **NIfTI (.nii.gz)** format:

- Spine segmentation mask
- Osteolytic lesion segmentation mask


Visualization Features
----------------------
All volumes and segmentation masks are displayed together in a single Napari viewer:

- CT volumes are shown as grayscale image layers
- Spine segmentation is overlaid in blue
- Lesion segmentation is overlaid in red
- Individual layers can be toggled on/off for interactive comparison
- Opacity and visibility can be adjusted directly in Napari

This setup enables detailed visual comparison between different energy reconstructions
and segmentation outputs.


Running the Visualization Script from the Command Line
-----------------------------------------------------
The visualization tool can be executed from the command line.  
You can either configure paths in the `config.py` file or provide them directly as arguments.

### Option 1 â€“ Use `config.py` (recommended)

If all paths and the patient ID are correctly set in `config.py`, the viewer can be launched without any arguments:

```bash
spinal-db-viewer
```

Before running, make sure to edit the following variables in `config.py`:
- `PATH_TO_DICOM_FOLDERS`
- `PATH_TO_SEGMENTATIONS`
- `ID_PATIENT`
- `NNUNET_REPO_PATH` (required for nnU-Net integration)

This is the simplest and recommended setup for regular use.

### Option 2 â€“ Installed CLI Tool (manual paths)

```bash
spinal-db-viewer \
  --path_to_DICOM_folders "/path/to/MM_DICOM_Dataset" \
  --path_to_segmentations "/path/to/MM_NIfTI_Segmentation" \
  --ID_patient "S840"
```

### Option 3 â€“ Run as Python Script

```bash
python Database_viewer_final.py \
  --path_to_DICOM_folders "/path/to/MM_DICOM_Dataset" \
  --path_to_segmentations "/path/to/MM_NIfTI_Segmentation" \
  --ID_patient "S840"
```

All three options are equivalent.  
If arguments are not provided, the values defined in `config.py` are used as defaults.

#### Arguments

- `--path_to_DICOM_folders`  
  Path to the DICOM folders, organized by patient ID and then by series description.

- `--path_to_segmentations`  
  Path to the NIfTI segmentation masks, organized by patient ID and mask type (`spine` or `lesions`).

- `--ID_patient`  
  Patient identifier (e.g., `S840`).

---------------------------------------------------------------------
Full Segmentation Pipeline (Python)
---------------------------------------------------------------------

Segmentation Script
-------------------
**`run_prediction_of_nnUNet_networks_on_TCIA_data_final.py`**

This script runs the complete nnU-Netâ€“based segmentation pipeline for a single patient,
starting directly from DICOM data and producing final lesion segmentations in the
original image space.

The pipeline always starts from a clean working directory to ensure reproducibility.
Any existing intermediate results for the selected patient are removed before processing.


Pipeline Steps
--------------
1. Conversion of ConvCT and VMI 40 keV DICOM series to NIfTI format
2. Spine segmentation from ConvCT data using nnU-Net
3. Reorientation of the spine segmentation back to the original image space
4. Lesion segmentation from VMI 40 keV images
5. Final reconstruction of lesion segmentation in the original image space

Running the Segmentation Pipeline
--------------------------------
The segmentation pipeline can be executed from the command line.  
You can either configure paths in the `config.py` file or provide them directly as arguments.

### Option 1 â€“ Use `config.py` (recommended)

If all paths and settings are correctly defined in `config.py`, the pipeline can be launched without any arguments:

```bash
spinal-run-nnunet
```

Before running, make sure to set the following variables in `config.py`:
- `PATH_TO_DICOM_FOLDERS`
- `PATH_TO_NNUNET_RESULTS`
- `ID_PATIENT`
- `NNUNET_REPO_PATH` (required for nnU-Net integration)
- `SPLIT_CONVCT_DEFAULT` (default split behavior)

This is the simplest and recommended setup for regular use.

### Option 2 â€“ Installed CLI Tool (manual paths)

```bash
spinal-run-nnunet \
  --path_to_DICOM_folders "/path/to/MM_DICOM_Dataset" \
  --path_to_nnunet_results "/path/to/nnUNet_trained_models" \
  --ID_patient "S840" \
  --split True
```

### Option 3 â€“ Run as Python Script

```bash
python run_prediction_of_nnUNet_networks_on_TCIA_data_final.py \
  --path_to_DICOM_folders "/path/to/MM_DICOM_Dataset" \
  --path_to_nnunet_results "/path/to/nnUNet_trained_models" \
  --ID_patient "S840" \
  --split True
```

All three options are equivalent.  
If arguments are not provided, the values defined in `config.py` are used as defaults.

#### Arguments

- `--path_to_DICOM_folders`  
  Path to the DICOM folders organized by patient ID and series description.

- `--path_to_nnunet_results`  
  Path to the folder containing trained nnU-Net models.

- `--ID_patient`  
  Patient identifier (e.g., `S840`).

- `--split`  
  If `True`, the data are split along the Z-axis to reduce memory requirements.


Notes on Multiprocessing
------------------------
- By default, the pipeline is configured for **Linux** and may use multiprocessing during nnU-Net inference.
- On **Windows**, Python multiprocessing can occasionally fail when running from a clean session.
- If inference fails on Windows, open `utils.py` and modify the function `run_nnunet_inference` to use **variant 2** (`predict_from_files_sequential`), which disables multiprocessing.
- This variant is slower but ensures safe and stable execution on Windows systems.
---

### Command-Line Inference Using nnUNet
The trained models can also be used with the default nnU-Net CLI for folder-based inference. For inference you can use the default [nnUNet inference functionalities](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/how_to_use_nnunet.md). 

To run a single model on all input images:

```bash
nnUNetv2_predict_from_modelfolder -i INPUT_FOLDER -o OUTPUT_FOLDER -m MODEL_FOLDER -f all
```





## Citation

If you use this code in your research, please cite our paper:
TO DO









